{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling with Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using [Spacy](https://spacy.io/) alongside sklearn in this notebook. \n",
    "\n",
    "We will also be finding good hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bay12_solution_eposts as solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "post, thread = solution.prepare.load_dfs('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_num</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45016</td>\n",
       "      <td>Mephansteras</td>\n",
       "      <td>Basically, this is where we talk about what ga...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45016</td>\n",
       "      <td>dakarian</td>\n",
       "      <td>The currently running or about to run games (i...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   thread_num          user  \\\n",
       "0       45016  Mephansteras   \n",
       "1       45016      dakarian   \n",
       "\n",
       "                                                text quotes  \n",
       "0  Basically, this is where we talk about what ga...     []  \n",
       "1  The currently running or about to run games (i...     []  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_num</th>\n",
       "      <th>thread_name</th>\n",
       "      <th>thread_label</th>\n",
       "      <th>thread_replies</th>\n",
       "      <th>thread_label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45016</td>\n",
       "      <td>Games Threshold Discussion and List [Vote for ...</td>\n",
       "      <td>other</td>\n",
       "      <td>5703</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>88720</td>\n",
       "      <td>New Player's Guide to the Subforum - New to Ma...</td>\n",
       "      <td>other</td>\n",
       "      <td>961</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   thread_num                                        thread_name thread_label  \\\n",
       "0       45016  Games Threshold Discussion and List [Vote for ...        other   \n",
       "1       88720  New Player's Guide to the Subforum - New to Ma...        other   \n",
       "\n",
       "   thread_replies  thread_label_id  \n",
       "0            5703                8  \n",
       "1             961                8  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thread.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type_name\n",
       "bastard             0\n",
       "beginners-mafia     1\n",
       "byor                2\n",
       "classic             3\n",
       "closed-setup        4\n",
       "cybrid              5\n",
       "kotm                6\n",
       "non-mafia-game      7\n",
       "other               8\n",
       "paranormal          9\n",
       "supernatural       10\n",
       "vanilla            11\n",
       "vengeful           12\n",
       "Name: type_id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = solution.prepare.load_label_map()\n",
    "label_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize our text features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Spacy model to get word/sentence vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using the large English model (~800 MB size) as shown [here](https://spacy.io/usage/models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_lg\n",
    "nlp = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp('a').vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Games Threshold Discussion and List [Vote for games now!]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_name = thread['thread_name'].iloc[0]\n",
    "doc = nlp(ex_name)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.07033058,  0.06838092, -0.00824608, -0.09143116], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average vector for the entire name\n",
    "doc.vector[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create \"final\" dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Not using the \"whole thread\" text because it takes a long time to calculate. \n",
    "Feel free to set `agg_post=['first', ' '.join]` to add the 'join' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def vectorize_dataset(thread, post, nlp, agg_post=['first']): \n",
    "    # Prepare thread, posts to use 'thread_num' as the index \n",
    "    thread = thread.set_index('thread_num')\n",
    "    post_texts = pd.concat(\n",
    "        [\n",
    "            thread[['thread_name']], \n",
    "            post.groupby('thread_num')['text'].agg(agg_post)\n",
    "        ], \n",
    "        axis='columns'\n",
    "    )\n",
    "     \n",
    "    # Get text features\n",
    "    vec_size = len(nlp('a').vector)\n",
    "    text_feature_names = [\n",
    "        '%s_%s' % (col, num) \n",
    "        for col, num \n",
    "        in itertools.product(post_texts.columns, range(vec_size)) \n",
    "    ]\n",
    "    \n",
    "    def vectorize_row(row, cols=post_texts.columns):\n",
    "        \"\"\"Vectorizes a row of texts.\"\"\"\n",
    "\n",
    "        res = np.array([])\n",
    "        for col in cols:\n",
    "            txt = row.loc[col][:100000]  # limit is 10x bigger, but we want to be safe :)\n",
    "            res = np.r_[res, nlp(txt).vector]\n",
    "        # v0 = nlp(row.loc['thread_name']).vector\n",
    "        # v1 = nlp(row.loc['first']).vector\n",
    "        # v2 = nlp(row.loc['join']).vector\n",
    "        return pd.Series(res, text_feature_names)\n",
    "    \n",
    "    thread_text_vectors = post_texts.apply(vectorize_row, axis='columns')\n",
    "    \n",
    "    # Add numeric features \n",
    "    thread_numeric_vectors = pd.DataFrame({\n",
    "        'posts': (thread['thread_replies'] + 1), \n",
    "        'posts_log': np.log(thread['thread_replies'] + 1), \n",
    "    })\n",
    "    \n",
    "    # Bring it together\n",
    "    X = pd.concat([thread_numeric_vectors, thread_text_vectors], axis='columns').astype('float')\n",
    "    try:\n",
    "        y = thread['thread_label_id']\n",
    "        y_aux = y.apply(lambda x: 0 if (x==label_map['other']) else 1).rename('is_game')\n",
    "    except Exception:\n",
    "        y = y_aux = None\n",
    "\n",
    "    return X, y, y_aux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z is our 'auxiliary objective' (whether it is the majority class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, z = vectorize_dataset(thread, post, nlp, agg_post=['first'])  # ['first', ' '.join]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = pd.Series(index=y.index, name=y.name)\n",
    "z1 = pd.Series(index=z.index, name=z.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things more readable, we'll use 'train', 'test' (instead of 'val') as the indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((268,), (90,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(X.index, test_size=0.25, random_state=99)\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what have I done so far? Let's list.\n",
    "\n",
    "- Selected title, first post, and maybe a concatenation of all posts as our \"documents\".\n",
    "- Turned each \"document\" into a vector, using pre-trained word vectors (the document vector is the average of the word vectors).\n",
    "- Added number of posts (and its log) as additional features.\n",
    "\n",
    "Note that we probably need to scale the latter two for some models, because the others components are normalized to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit models (pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_z = Pipeline([\n",
    "    ('scale', StandardScaler()), \n",
    "    ('cls', RandomForestClassifier(n_estimators=100, max_depth=2, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('cls', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_z.fit(X.loc[train], z.loc[train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "z1.loc[train] = pipe_z.predict(X.loc[train])\n",
    "z1.loc[test] = pipe_z.predict(X.loc[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aux target (z).\n",
      "Train:\n",
      "   Accuracy: 0.9402985074626866\n",
      "   Confusion:\n",
      "[[141   6]\n",
      " [ 10 111]]\n",
      "\n",
      "Test\n",
      "   Accuracy: 0.8666666666666667\n",
      "   Confusion:\n",
      "[[52  2]\n",
      " [10 26]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "\"\"\"Aux target (z).\n",
    "Train:\n",
    "   Accuracy: {}\n",
    "   Confusion:\n",
    "{}\n",
    "\n",
    "Test\n",
    "   Accuracy: {}\n",
    "   Confusion:\n",
    "{}\n",
    "\"\"\".format(\n",
    "    accuracy_score(z.loc[train], z1.loc[train]),\n",
    "    confusion_matrix(z.loc[train], z1.loc[train]),\n",
    "    accuracy_score(z.loc[test], z1.loc[test]),\n",
    "    confusion_matrix(z.loc[test], z1.loc[test]),\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p2 = z.loc[train][z.loc[train] == 1].dropna().index\n",
    "test_p2 = z1.loc[test][z1.loc[test] == 1].dropna().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_y = Pipeline([\n",
    "    ('scale', StandardScaler()), \n",
    "    ('cls', RandomForestClassifier(n_estimators=200, max_depth=3, max_leaf_nodes=10, random_state=68))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scale', StandardScaler(copy=True, with_mean=True, with_std=True)), ('cls', RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=10,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=200, n_jobs=None,\n",
       "            oob_score=False, random_state=68, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_y.fit(X.loc[train_p2], y.loc[train_p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1.loc[train] = label_map['other']\n",
    "y1.loc[train_p2] = pipe_y.predict(X.loc[train_p2])\n",
    "\n",
    "y1.loc[test] = label_map['other']\n",
    "y1.loc[test_p2] = pipe_y.predict(X.loc[test_p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aux target (y).\n",
      "Train:\n",
      "   Accuracy: 0.9256198347107438\n",
      "   Confusion:\n",
      "[[10  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0 19  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 11  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 14  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 26  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 18  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  3  0  0]\n",
      " [ 0  2  0  0  1  0  0  0  0  0  5  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  6]]\n",
      "\n",
      "Test\n",
      "   Accuracy: 0.5357142857142857\n",
      "   Confusion:\n",
      "[[0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 5 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 9 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "\"\"\"Aux target (y).\n",
    "Train:\n",
    "   Accuracy: {}\n",
    "   Confusion:\n",
    "{}\n",
    "\n",
    "Test\n",
    "   Accuracy: {}\n",
    "   Confusion:\n",
    "{}\n",
    "\"\"\".format(\n",
    "    accuracy_score(y.loc[train_p2], y1.loc[train_p2]),\n",
    "    confusion_matrix(y.loc[train_p2], y1.loc[train_p2]),\n",
    "    accuracy_score(y.loc[test_p2], y1.loc[test_p2]),\n",
    "    confusion_matrix(y.loc[test_p2], y1.loc[test_p2]),\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well obviously the algorithm overfit on the majority class (the fifth column, with '26' on the diagonal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the resulting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final target (y).\n",
      "Train:\n",
      "   Accuracy: 0.9664179104477612\n",
      "   Confusion:\n",
      "[[ 10   0   0   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0  19   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  11   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  14   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  26   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   2   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 147   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  18   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   3   0   0]\n",
      " [  0   2   0   0   1   0   0   0   0   0   0   5   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   6]]\n",
      "\n",
      "Test\n",
      "   Accuracy: 0.7444444444444445\n",
      "   Confusion:\n",
      "[[ 0  0  0  0  1  0  0  2  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  9  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  1  0  0 52  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "\"\"\"Final target (y).\n",
    "Train:\n",
    "   Accuracy: {}\n",
    "   Confusion:\n",
    "{}\n",
    "\n",
    "Test\n",
    "   Accuracy: {}\n",
    "   Confusion:\n",
    "{}\n",
    "\"\"\".format(\n",
    "    accuracy_score(y.loc[train], y1.loc[train]),\n",
    "    confusion_matrix(y.loc[train], y1.loc[train]),\n",
    "    accuracy_score(y.loc[test], y1.loc[test]),\n",
    "    confusion_matrix(y.loc[test], y1.loc[test]),\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model consists of two parts - let's see how well we did altogether:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.75 accuracy! That's pretty good for a slightly-tuned model. That's significantly better than the baseline of ~0.55!\n",
    "\n",
    "We still have some classes that aren't predicted in the validation set (actually quite a few - 7 out of 12 have 0 predicted!), which is pretty bad (obviously). \n",
    "However, we did predict something for all but 3 of them on the training set (and those 3 had 4 threads in total... so...). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit on full set, predict on output set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "post2, thread2 = solution.prepare.load_dfs('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2, _, _ = vectorize_dataset(thread2, post2, nlp, agg_post=['first'])  # ['first', ' '.join]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, not retraining:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((236,), (129,))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict z2\n",
    "z2 = pd.Series(pipe_z.predict(X2), X2.index)\n",
    "pred_p2 = z2[z2 == 1].dropna().index\n",
    "z2.shape, pred_p2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict y2\n",
    "y2 = pd.Series(label_map['other'], index=X2.index, name=y.name)\n",
    "y2.loc[pred_p2] = pipe_y.predict(X2.loc[pred_p2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_num</th>\n",
       "      <th>thread_label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89396</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89665</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89865</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>91240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91413</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   thread_num  thread_label_id\n",
       "0       89396                8\n",
       "1       89665                4\n",
       "2       89865                4\n",
       "3       91240                1\n",
       "4       91413                4"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = y2.reset_index()[['thread_num', 'thread_label_id']]\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Exporting next to the notebooks - the files are small, but usually you don't want to do this.\n",
    "out_dir = os.path.abspath('4_output')\n",
    "os.makedirs(out_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\n",
    "    os.path.join(out_dir, 'anatoly_m4_predict.csv'),\n",
    "    index=False, header=True, encoding='utf-8', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-mafia",
   "language": "python",
   "name": "env-mafia"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
